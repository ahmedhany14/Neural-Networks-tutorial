{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 17:31:51.732100: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 17:31:51.732384: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 17:31:51.734509: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 17:31:51.762737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 17:31:52.303067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError,BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.activations import relu, elu, sigmoid, softmax,linear\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>219.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>182.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>154.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>20.6</td>\n",
       "      <td>223.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>200.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>18.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>288.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>17.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>256.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>13.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>16.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1016.9</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>186.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>16.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>18.3</td>\n",
       "      <td>185.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T    TM    Tm     SLP     H   VV     V    VM      PM 2.5\n",
       "0      7.4   9.8   4.8  1017.6  93.0  0.5   4.3   9.4  219.720833\n",
       "1      7.8  12.7   4.4  1018.5  87.0  0.6   4.4  11.1  182.187500\n",
       "2      6.7  13.4   2.4  1019.4  82.0  0.6   4.8  11.1  154.037500\n",
       "3      8.6  15.5   3.3  1018.7  72.0  0.8   8.1  20.6  223.208333\n",
       "4     12.4  20.9   4.4  1017.3  61.0  1.3   8.7  22.2  200.645833\n",
       "...    ...   ...   ...     ...   ...  ...   ...   ...         ...\n",
       "1088  18.1  24.0  11.2  1015.4  56.0  1.8  15.9  25.9  288.416667\n",
       "1089  17.8  25.0  10.7  1015.8  54.0  2.3   9.4  22.2  256.833333\n",
       "1090  13.9  24.5  11.4  1015.0  95.0  0.6   8.7  14.8  169.000000\n",
       "1091  16.3  23.0   9.8  1016.9  78.0  1.1   7.4  16.5  186.041667\n",
       "1092  16.3  23.4   9.0  1017.3  68.0  1.3   7.8  18.3  185.583333\n",
       "\n",
       "[1092 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'/home/ahmed/Ai/Neural-Networks-tutorial/data/Real_Combine.csv')\n",
    "data.dropna(inplace=True)  \n",
    "X, Y = data.iloc[:, :-1], data.iloc[:, -1] \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparameters):\n",
    "    model = Sequential()  # The Sequential model, which i will use to build the network\n",
    "\n",
    "    for i in range(\n",
    "        hyperparameters.Int(\"number_of_hidden_layers\", min_value=2, max_value=20)\n",
    "    ):  # which means that i will have a number of hidden layers between 2 and 20\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hyperparameters.Int(\n",
    "                    \"neurons_of_layer_\" + str(i), min_value=16, max_value=256, step=16\n",
    "                ),  # The number of neurons in each layer will be between 16 and 256)\n",
    "                activation=hyperparameters.Choice(\n",
    "                    \"activation_of_layer_\" + str(i),\n",
    "                    values=['relu', 'softmax', 'linear'],\n",
    "                ),\n",
    "            )  # The activation function of each layer will be one of the following functions: relu, elu, sigmoid, softmax, linear\n",
    "        )\n",
    "        model.add(Dropout(hyperparameters.Float(\"dropout_of_layer_\" + str(i), 0, 0.5)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hyperparameters.Choice(\n",
    "                \"learning_rate\",\n",
    "                values=[1e-2, 1e-3, 1e-4],\n",
    "            )\n",
    "        ),\n",
    "        loss=MeanSquaredError(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory=\"hyperparameters\", # for saving the logs and checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "number_of_hidden_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': 'linear'}\n",
      "neurons_of_layer_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 16, 'sampling': 'linear'}\n",
      "activation_of_layer_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'softmax', 'linear'], 'ordered': False}\n",
      "dropout_of_layer_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "neurons_of_layer_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 16, 'sampling': 'linear'}\n",
      "activation_of_layer_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'softmax', 'linear'], 'ordered': False}\n",
      "dropout_of_layer_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((764, 8), (328, 8), (764,), (328,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.0\n",
      "\n",
      "Best val_accuracy So Far: 0.04268292710185051\n",
      "Total elapsed time: 00h 00m 37s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparameters/untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "number_of_hidden_layers: 10\n",
      "neurons_of_layer_0: 208\n",
      "activation_of_layer_0: linear\n",
      "dropout_of_layer_0: 0.3508364888783842\n",
      "neurons_of_layer_1: 176\n",
      "activation_of_layer_1: linear\n",
      "dropout_of_layer_1: 0.2689344564475333\n",
      "learning_rate: 0.001\n",
      "neurons_of_layer_2: 224\n",
      "activation_of_layer_2: softmax\n",
      "dropout_of_layer_2: 0.43035407076300547\n",
      "neurons_of_layer_3: 208\n",
      "activation_of_layer_3: relu\n",
      "dropout_of_layer_3: 0.2687993395402663\n",
      "neurons_of_layer_4: 80\n",
      "activation_of_layer_4: linear\n",
      "dropout_of_layer_4: 0.12975247738834494\n",
      "neurons_of_layer_5: 16\n",
      "activation_of_layer_5: linear\n",
      "dropout_of_layer_5: 0.13146476384411687\n",
      "neurons_of_layer_6: 32\n",
      "activation_of_layer_6: relu\n",
      "dropout_of_layer_6: 0.13510299071710108\n",
      "neurons_of_layer_7: 96\n",
      "activation_of_layer_7: linear\n",
      "dropout_of_layer_7: 0.24073043470922068\n",
      "neurons_of_layer_8: 144\n",
      "activation_of_layer_8: relu\n",
      "dropout_of_layer_8: 0.32864833779192065\n",
      "neurons_of_layer_9: 192\n",
      "activation_of_layer_9: softmax\n",
      "dropout_of_layer_9: 0.03422276490282822\n",
      "neurons_of_layer_10: 80\n",
      "activation_of_layer_10: linear\n",
      "dropout_of_layer_10: 0.45837193252709274\n",
      "neurons_of_layer_11: 176\n",
      "activation_of_layer_11: relu\n",
      "dropout_of_layer_11: 0.01440017924595871\n",
      "Score: 0.04268292710185051\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "number_of_hidden_layers: 12\n",
      "neurons_of_layer_0: 208\n",
      "activation_of_layer_0: linear\n",
      "dropout_of_layer_0: 0.44078897359697794\n",
      "neurons_of_layer_1: 240\n",
      "activation_of_layer_1: linear\n",
      "dropout_of_layer_1: 0.03520722944678284\n",
      "learning_rate: 0.0001\n",
      "neurons_of_layer_2: 208\n",
      "activation_of_layer_2: linear\n",
      "dropout_of_layer_2: 0.4614907943985159\n",
      "neurons_of_layer_3: 128\n",
      "activation_of_layer_3: linear\n",
      "dropout_of_layer_3: 0.20622129330638134\n",
      "neurons_of_layer_4: 128\n",
      "activation_of_layer_4: relu\n",
      "dropout_of_layer_4: 0.4624098040857697\n",
      "neurons_of_layer_5: 128\n",
      "activation_of_layer_5: relu\n",
      "dropout_of_layer_5: 0.1771082117049817\n",
      "neurons_of_layer_6: 224\n",
      "activation_of_layer_6: relu\n",
      "dropout_of_layer_6: 0.2521421317229473\n",
      "neurons_of_layer_7: 256\n",
      "activation_of_layer_7: linear\n",
      "dropout_of_layer_7: 0.4026395593194873\n",
      "neurons_of_layer_8: 16\n",
      "activation_of_layer_8: relu\n",
      "dropout_of_layer_8: 0.0\n",
      "neurons_of_layer_9: 16\n",
      "activation_of_layer_9: relu\n",
      "dropout_of_layer_9: 0.0\n",
      "neurons_of_layer_10: 16\n",
      "activation_of_layer_10: relu\n",
      "dropout_of_layer_10: 0.0\n",
      "neurons_of_layer_11: 16\n",
      "activation_of_layer_11: relu\n",
      "dropout_of_layer_11: 0.0\n",
      "Score: 0.014227642367283503\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "number_of_hidden_layers: 8\n",
      "neurons_of_layer_0: 96\n",
      "activation_of_layer_0: softmax\n",
      "dropout_of_layer_0: 0.05097427808515126\n",
      "neurons_of_layer_1: 160\n",
      "activation_of_layer_1: relu\n",
      "dropout_of_layer_1: 0.45856209492502\n",
      "learning_rate: 0.01\n",
      "neurons_of_layer_2: 16\n",
      "activation_of_layer_2: relu\n",
      "dropout_of_layer_2: 0.0\n",
      "neurons_of_layer_3: 16\n",
      "activation_of_layer_3: relu\n",
      "dropout_of_layer_3: 0.0\n",
      "neurons_of_layer_4: 16\n",
      "activation_of_layer_4: relu\n",
      "dropout_of_layer_4: 0.0\n",
      "neurons_of_layer_5: 16\n",
      "activation_of_layer_5: relu\n",
      "dropout_of_layer_5: 0.0\n",
      "neurons_of_layer_6: 16\n",
      "activation_of_layer_6: relu\n",
      "dropout_of_layer_6: 0.0\n",
      "neurons_of_layer_7: 16\n",
      "activation_of_layer_7: relu\n",
      "dropout_of_layer_7: 0.0\n",
      "Score: 0.0\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "number_of_hidden_layers: 15\n",
      "neurons_of_layer_0: 112\n",
      "activation_of_layer_0: linear\n",
      "dropout_of_layer_0: 0.21618149113950852\n",
      "neurons_of_layer_1: 128\n",
      "activation_of_layer_1: softmax\n",
      "dropout_of_layer_1: 0.26068332195085675\n",
      "learning_rate: 0.001\n",
      "neurons_of_layer_2: 192\n",
      "activation_of_layer_2: softmax\n",
      "dropout_of_layer_2: 0.09024527945072369\n",
      "neurons_of_layer_3: 96\n",
      "activation_of_layer_3: linear\n",
      "dropout_of_layer_3: 0.49046083519578765\n",
      "neurons_of_layer_4: 208\n",
      "activation_of_layer_4: linear\n",
      "dropout_of_layer_4: 0.35300566947207535\n",
      "neurons_of_layer_5: 240\n",
      "activation_of_layer_5: softmax\n",
      "dropout_of_layer_5: 0.004674698129435495\n",
      "neurons_of_layer_6: 208\n",
      "activation_of_layer_6: softmax\n",
      "dropout_of_layer_6: 0.25362628101324713\n",
      "neurons_of_layer_7: 80\n",
      "activation_of_layer_7: linear\n",
      "dropout_of_layer_7: 0.43580379515626116\n",
      "neurons_of_layer_8: 80\n",
      "activation_of_layer_8: relu\n",
      "dropout_of_layer_8: 0.14377025029520502\n",
      "neurons_of_layer_9: 48\n",
      "activation_of_layer_9: linear\n",
      "dropout_of_layer_9: 0.18772799167672316\n",
      "neurons_of_layer_10: 256\n",
      "activation_of_layer_10: relu\n",
      "dropout_of_layer_10: 0.24107463596063605\n",
      "neurons_of_layer_11: 64\n",
      "activation_of_layer_11: relu\n",
      "dropout_of_layer_11: 0.05868489435148716\n",
      "neurons_of_layer_12: 16\n",
      "activation_of_layer_12: relu\n",
      "dropout_of_layer_12: 0.0\n",
      "neurons_of_layer_13: 16\n",
      "activation_of_layer_13: relu\n",
      "dropout_of_layer_13: 0.0\n",
      "neurons_of_layer_14: 16\n",
      "activation_of_layer_14: relu\n",
      "dropout_of_layer_14: 0.0\n",
      "Score: 0.0\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "number_of_hidden_layers: 17\n",
      "neurons_of_layer_0: 16\n",
      "activation_of_layer_0: relu\n",
      "dropout_of_layer_0: 0.2578327287822427\n",
      "neurons_of_layer_1: 64\n",
      "activation_of_layer_1: linear\n",
      "dropout_of_layer_1: 0.3539465731586251\n",
      "learning_rate: 0.01\n",
      "neurons_of_layer_2: 176\n",
      "activation_of_layer_2: relu\n",
      "dropout_of_layer_2: 0.49329735822381393\n",
      "neurons_of_layer_3: 64\n",
      "activation_of_layer_3: softmax\n",
      "dropout_of_layer_3: 0.4768052606970145\n",
      "neurons_of_layer_4: 208\n",
      "activation_of_layer_4: softmax\n",
      "dropout_of_layer_4: 0.003308329298904844\n",
      "neurons_of_layer_5: 64\n",
      "activation_of_layer_5: linear\n",
      "dropout_of_layer_5: 0.09436575576590284\n",
      "neurons_of_layer_6: 208\n",
      "activation_of_layer_6: linear\n",
      "dropout_of_layer_6: 0.473510781985041\n",
      "neurons_of_layer_7: 48\n",
      "activation_of_layer_7: linear\n",
      "dropout_of_layer_7: 0.2535617384079839\n",
      "neurons_of_layer_8: 32\n",
      "activation_of_layer_8: relu\n",
      "dropout_of_layer_8: 0.35570444156601\n",
      "neurons_of_layer_9: 240\n",
      "activation_of_layer_9: relu\n",
      "dropout_of_layer_9: 0.10104496888196535\n",
      "neurons_of_layer_10: 192\n",
      "activation_of_layer_10: linear\n",
      "dropout_of_layer_10: 0.012308837667375894\n",
      "neurons_of_layer_11: 96\n",
      "activation_of_layer_11: relu\n",
      "dropout_of_layer_11: 0.10101625273977022\n",
      "neurons_of_layer_12: 112\n",
      "activation_of_layer_12: softmax\n",
      "dropout_of_layer_12: 0.18799387964934816\n",
      "neurons_of_layer_13: 160\n",
      "activation_of_layer_13: softmax\n",
      "dropout_of_layer_13: 0.42098142972527464\n",
      "neurons_of_layer_14: 144\n",
      "activation_of_layer_14: softmax\n",
      "dropout_of_layer_14: 0.041519654792045835\n",
      "neurons_of_layer_15: 16\n",
      "activation_of_layer_15: relu\n",
      "dropout_of_layer_15: 0.0\n",
      "neurons_of_layer_16: 16\n",
      "activation_of_layer_16: relu\n",
      "dropout_of_layer_16: 0.0\n",
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_hidden_layers': 10,\n",
       " 'neurons_of_layer_0': 208,\n",
       " 'activation_of_layer_0': 'linear',\n",
       " 'dropout_of_layer_0': 0.3508364888783842,\n",
       " 'neurons_of_layer_1': 176,\n",
       " 'activation_of_layer_1': 'linear',\n",
       " 'dropout_of_layer_1': 0.2689344564475333,\n",
       " 'learning_rate': 0.001,\n",
       " 'neurons_of_layer_2': 224,\n",
       " 'activation_of_layer_2': 'softmax',\n",
       " 'dropout_of_layer_2': 0.43035407076300547,\n",
       " 'neurons_of_layer_3': 208,\n",
       " 'activation_of_layer_3': 'relu',\n",
       " 'dropout_of_layer_3': 0.2687993395402663,\n",
       " 'neurons_of_layer_4': 80,\n",
       " 'activation_of_layer_4': 'linear',\n",
       " 'dropout_of_layer_4': 0.12975247738834494,\n",
       " 'neurons_of_layer_5': 16,\n",
       " 'activation_of_layer_5': 'linear',\n",
       " 'dropout_of_layer_5': 0.13146476384411687,\n",
       " 'neurons_of_layer_6': 32,\n",
       " 'activation_of_layer_6': 'relu',\n",
       " 'dropout_of_layer_6': 0.13510299071710108,\n",
       " 'neurons_of_layer_7': 96,\n",
       " 'activation_of_layer_7': 'linear',\n",
       " 'dropout_of_layer_7': 0.24073043470922068,\n",
       " 'neurons_of_layer_8': 144,\n",
       " 'activation_of_layer_8': 'relu',\n",
       " 'dropout_of_layer_8': 0.32864833779192065,\n",
       " 'neurons_of_layer_9': 192,\n",
       " 'activation_of_layer_9': 'softmax',\n",
       " 'dropout_of_layer_9': 0.03422276490282822,\n",
       " 'neurons_of_layer_10': 80,\n",
       " 'activation_of_layer_10': 'linear',\n",
       " 'dropout_of_layer_10': 0.45837193252709274,\n",
       " 'neurons_of_layer_11': 176,\n",
       " 'activation_of_layer_11': 'relu',\n",
       " 'dropout_of_layer_11': 0.01440017924595871}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 46 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">46,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │         \u001b[38;5;34m1,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m176\u001b[0m)            │        \u001b[38;5;34m36,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m176\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │        \u001b[38;5;34m39,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │        \u001b[38;5;34m46,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m16,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m3,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)            │        \u001b[38;5;34m13,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │        \u001b[38;5;34m27,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m193\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,833</span> (737.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m188,833\u001b[0m (737.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,833</span> (737.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m188,833\u001b[0m (737.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model = tuner.get_best_models()[0]\n",
    "final_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
